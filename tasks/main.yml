---
- name: download Hadoop
  get_url:
    url: "http://apache-mirror.rbc.ru/pub/apache/hadoop/common/hadoop-{{ hadoop_version }}/hadoop-{{ hadoop_version }}.tar.gz"
    dest: /root/hadoop-{{ hadoop_version }}.tar.gz
    force: no
    checksum: "{{ hadoop_checksum_algo }}:{{ hadoop_checksum }}"

- name: install tar
  package: name=tar state=present
  when: ansible_os_family != 'Elbrus'

- name: unpack Hadoop
  unarchive: copy=no src="/root/hadoop-{{ hadoop_version }}.tar.gz" dest={{ hadoop_unarchive_prefix }}
  when: not ansible_check_mode

- name: install rsync
  apt: name=rsync

- name: create {{ hadoop_distr_prefix }}
  command: rsync -av --exclude=conf/ {{ hadoop_unarchive_prefix }}/hadoop-{{ hadoop_version }}/ {{ hadoop_distr_prefix }}-{{ env_name }}-{{ hadoop_version }}/ creates={{ hadoop_distr_prefix }}-{{ env_name }}-{{ hadoop_version }}

- name: create a -current link
  file: state=link src={{ hadoop_distr_prefix }}-{{ env_name }}-{{ hadoop_version }} dest={{ hadoop_distr_prefix }}-{{ env_name }}-current
  when: not ansible_check_mode

- name: add Hadoop user
  user: name={{ hadoop_user }} shell={{ hadoop_user_shell }} state=present

- name: make {{ hadoop_var_prefix }}
  file: path={{ hadoop_var_prefix }} state=directory owner={{ hadoop_user }} group={{ hadoop_user }} mode=0755

- name: put exclusion list
  template: src=exclusion-list dest={{ hadoop_var_prefix }}/exclusion-list backup=yes
  notify: refresh nodes

- name: make {{ hadoop_distr_prefix }}-{{ env_name }}-{{ hadoop_version }}/conf
  file: path={{ hadoop_distr_prefix }}-{{ env_name }}-{{ hadoop_version }}/conf state=directory owner=root group=root mode=0755

- name: make /etc/hadoop-{{ env_name }}
  file: path=/etc/hadoop-{{ env_name }} state=directory owner=root group=root mode=0755

- name: put /etc/hadoop-{{ env_name }}/core-site.xml
  template: src=core-site.xml dest=/etc/hadoop-{{ env_name }}/core-site.xml owner=root group=root mode=0644 backup=yes

- name: put {{ hadoop_distr_prefix }}-{{ env_name }}-{{ hadoop_version }}/conf/core-site.xml
  file: state=link src=/etc/hadoop-{{ env_name }}/core-site.xml dest={{ hadoop_distr_prefix }}-{{ env_name }}-{{ hadoop_version }}/conf/core-site.xml
  when: not ansible_check_mode

- name: put /etc/hadoop-{{ env_name }}/hdfs-site.xml
  template: src=hdfs-site.xml dest=/etc/hadoop-{{ env_name }}/hdfs-site.xml owner=root group=root mode=0644 backup=yes

- name: put {{ hadoop_distr_prefix }}-{{ env_name }}-{{ hadoop_version }}/conf/hdfs-site.xml
  file: state=link src=/etc/hadoop-{{ env_name }}/hdfs-site.xml dest={{ hadoop_distr_prefix }}-{{ env_name }}-{{ hadoop_version }}/conf/hdfs-site.xml

- name: put /etc/hadoop-{{ env_name }}/hadoop-env.sh
  template: src=hadoop-env.sh dest=/etc/hadoop-{{ env_name }}/hadoop-env.sh owner=root group=root mode=0644 backup=yes

- name: put {{ hadoop_distr_prefix }}-{{ env_name }}-{{ hadoop_version }}/conf/hadoop-env.sh
  file: state=link src=/etc/hadoop-{{ env_name }}/hadoop-env.sh dest={{ hadoop_distr_prefix }}-{{ env_name }}-{{ hadoop_version }}/conf/hadoop-env.sh

- name: put /etc/hadoop-{{ env_name }}/hadoop-metrics.properties
  template: src=hadoop-metrics.properties dest=/etc/hadoop-{{ env_name }}/hadoop-metrics.properties owner=root group=root mode=0644 backup=yes

- name: put {{ hadoop_distr_prefix }}-{{ env_name }}-{{ hadoop_version }}/conf/hadoop-metrics.properties
  file:
    state: link
    src: "/etc/hadoop-{{ env_name }}/hadoop-metrics.properties"
    dest: "{{ hadoop_distr_prefix }}-{{ env_name }}-{{ hadoop_version }}/conf/hadoop-metrics.properties"

- name: put "/etc/hadoop-{{ env_name }}/jmx_prometheus_javaagent.yaml"
  template: src=jmx_prometheus_javaagent.yaml dest=/etc/hadoop-{{ env_name }}/jmx_prometheus_javaagent.yaml owner=root group=root mode=0644 backup=yes

- name: create {{ hadoop_distr_prefix }}-{{ env_name }}-{{ hadoop_version }}/conf/jmx_prometheus_javaagent.yaml
  file:
    state: link
    src: "/etc/hadoop-{{ env_name }}/jmx_prometheus_javaagent.yaml"
    dest: "{{ hadoop_distr_prefix }}-{{ env_name }}-{{ hadoop_version }}/conf/jmx_prometheus_javaagent.yaml"

- name: put /etc/hadoop-{{ env_name }}/yarn-env.sh
  template: src=yarn-env.sh dest=/etc/hadoop-{{ env_name }}/yarn-env.sh owner=root group=root mode=0644 backup=yes
  when: not disable_yarn

- name: put {{ hadoop_distr_prefix }}-{{ env_name }}-{{ hadoop_version }}/conf/yarn-env.sh
  file: state=link src=/etc/hadoop-{{ env_name }}/yarn-env.sh dest={{ hadoop_distr_prefix }}-{{ env_name }}-{{ hadoop_version }}/conf/yarn-env.sh
  when: not disable_yarn

- name: put /etc/hadoop-{{ env_name }}/yarn-site.xml
  template: src=yarn-site.xml dest=/etc/hadoop-{{ env_name }}/yarn-site.xml owner=root group=root mode=0644 backup=yes
  when: not disable_yarn

- name: put {{ hadoop_distr_prefix }}-{{ env_name }}-{{ hadoop_version }}/conf/yarn-site.xml
  file: state=link src=/etc/hadoop-{{ env_name }}/yarn-site.xml dest={{ hadoop_distr_prefix }}-{{ env_name }}-{{ hadoop_version }}/conf/yarn-site.xml
  when: not disable_yarn

- name: put /etc/hadoop-{{ env_name }}/mapred-site.xml
  template: src=mapred-site.xml dest=/etc/hadoop-{{ env_name }}/mapred-site.xml owner=root group=root mode=0644 backup=yes
  when: not disable_yarn

- name: put {{ hadoop_distr_prefix }}-{{ env_name }}-{{ hadoop_version }}/conf/mapred-site.xml
  file: state=link src=/etc/hadoop-{{ env_name }}/mapred-site.xml dest={{ hadoop_distr_prefix }}-{{ env_name }}-{{ hadoop_version }}/conf/mapred-site.xml
  when: not disable_yarn

- name: create {{ hadoop_distr_prefix }}-{{ env_name }}-{{ hadoop_version }}/lib/native/Linux-amd64-64
  file: state=directory path={{ hadoop_distr_prefix }}-{{ env_name }}-{{ hadoop_version }}/lib/native/Linux-amd64-64

- name: make {{ hadoop_distr_prefix }}-{{ env_name }}-{{ hadoop_version }}/logs
  file: path={{ hadoop_distr_prefix }}-{{ env_name }}-{{ hadoop_version }}/logs state=directory owner={{ hadoop_user }} group={{ hadoop_user }} mode=0755

- name: make a link to libhadoop.so
  file:
    state: link
    src: "{{ hadoop_distr_prefix }}-{{ env_name }}-{{ hadoop_version }}/lib/native/libhadoop.so"
    dest: "{{ hadoop_distr_prefix }}-{{ env_name }}-{{ hadoop_version }}/lib/native/Linux-amd64-64/libhadoop.so"

- name: make a link to libhdfs.so
  file:
    state: link
    src: "{{ hadoop_distr_prefix }}-{{ env_name }}-{{ hadoop_version }}/lib/native/libhdfs.so"
    dest: "{{ hadoop_distr_prefix }}-{{ env_name }}-{{ hadoop_version }}/lib/native/Linux-amd64-64/libhdfs.so"

- name: download the Prom JMX exporter
  get_url:
    url: "https://repo1.maven.org/maven2/io/prometheus/jmx/jmx_prometheus_javaagent/0.3.1/jmx_prometheus_javaagent-0.3.1.jar"
    dest: "{{ hadoop_distr_prefix }}-{{ env_name }}-{{ hadoop_version }}/lib/jmx_prometheus_javaagent-0.3.1.jar"
